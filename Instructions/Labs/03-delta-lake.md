---
lab:
  title: åœ¨ Apache Spark ä¸­ä½¿ç”¨ Delta è¡¨
  module: Work with Delta Lake tables in Microsoft Fabric
---

# åœ¨ Apache Spark ä¸­ä½¿ç”¨ Delta è¡¨

Microsoft Fabric æ¹–å±‹ä¸­çš„è¡¨åŸºäºå¼€æº Delta Lake æ ¼å¼ã€‚ Delta Lake æ·»åŠ äº†å¯¹æ‰¹å¤„ç†å’Œæµå¼æ•°æ®çš„å…³ç³»è¯­ä¹‰çš„æ”¯æŒã€‚ åœ¨æœ¬ç»ƒä¹ ä¸­ï¼Œä½ å°†åˆ›å»º Delta è¡¨å¹¶ä½¿ç”¨ SQL æŸ¥è¯¢æµè§ˆæ•°æ®ã€‚

å®Œæˆæ­¤ç»ƒä¹ å¤§çº¦éœ€è¦ **45** åˆ†é’Ÿ

> [!Note] 
> ä½ éœ€è¦è®¿é—® [Microsoft Fabric](https://learn.microsoft.com/fabric/get-started/fabric-trial) ç§Ÿæˆ·æ‰èƒ½å®Œæˆæœ¬ç»ƒä¹ ã€‚

## åˆ›å»ºå·¥ä½œåŒº

åœ¨ Fabric ä¸­å¤„ç†æ•°æ®ä¹‹å‰ï¼Œè¯·åœ¨å¯ç”¨ Fabric å®¹é‡çš„ç§Ÿæˆ·ä¸­åˆ›å»ºä¸€ä¸ªå·¥ä½œåŒºã€‚

1. åœ¨æµè§ˆå™¨ä¸­ï¼Œå¯¼èˆªåˆ° [Microsoft Fabric ä¸»é¡µ](https://app.fabric.microsoft.com/home?experience=fabric-developer) (`https://app.fabric.microsoft.com/home?experience=fabric-developer`)ï¼Œä½¿ç”¨ Fabric å‡­æ®ç™»å½•ã€‚
1. åœ¨å·¦ä¾§èœå•æ ä¸­ï¼Œé€‰æ‹©â€œå·¥ä½œåŒºâ€ï¼ˆå›¾æ ‡ç±»ä¼¼äº &#128455;ï¼‰ã€‚
1. æ–°å»ºä¸€ä¸ªå·¥ä½œåŒºå¹¶ä¸ºå…¶æŒ‡å®šåç§°ï¼Œå¹¶åœ¨â€œé«˜çº§â€éƒ¨åˆ†é€‰æ‹©åŒ…å« Fabric å®¹é‡ï¼ˆè¯•ç”¨ç‰ˆã€é«˜çº§ç‰ˆæˆ– Fabricï¼‰çš„è®¸å¯æ¨¡å¼  ã€‚
1. æ‰“å¼€æ–°å·¥ä½œåŒºæ—¶ï¼Œå®ƒåº”ä¸ºç©ºã€‚

    ![Fabric ä¸­ç©ºå·¥ä½œåŒºçš„å±å¹•æˆªå›¾ã€‚](./Images/new-workspace.png)

## åˆ›å»ºæ¹–å±‹å¹¶ä¸Šä¼ æ–‡ä»¶

ç°åœ¨å·²ç»æœ‰äº†å·¥ä½œåŒºï¼Œå¯ä»¥ä¸ºæ•°æ®åˆ›å»ºæ•°æ®æ¹–å±‹äº†ã€‚

1. åœ¨å·¦ä¾§èœå•ä¸Šï¼Œé€‰æ‹©â€œ**åˆ›å»º**â€ã€‚ åœ¨â€œ*æ–°å»º*â€é¡µçš„ *â€œæ•°æ®å·¥ç¨‹â€* éƒ¨åˆ†ä¸‹ï¼Œé€‰æ‹©â€œ**æ¹–å±‹**â€ã€‚ ä¸ºå…¶æŒ‡å®šå”¯ä¸€çš„åç§°ã€‚

    >**å¤‡æ³¨**ï¼šå¦‚æœæœªå°†â€œ**åˆ›å»º**â€é€‰é¡¹å›ºå®šåˆ°è¾¹æ ï¼Œåˆ™éœ€è¦é¦–å…ˆé€‰æ‹©çœç•¥å· (**...**) é€‰é¡¹ã€‚

    å¤§çº¦ä¸€åˆ†é’Ÿåï¼Œä¸€ä¸ªæ–°çš„æ¹–å±‹åˆ›å»ºå®Œæˆï¼š

    ![æ–°æ¹–å±‹çš„å±å¹•æˆªå›¾ã€‚](./Images/new-lakehouse.png)

1. æŸ¥çœ‹æ–°çš„æ¹–å±‹ï¼Œæ³¨æ„å·¦ä¾§çš„**èµ„æºç®¡ç†å™¨**çª—æ ¼å¯ç”¨äºæµè§ˆæ¹–å±‹ä¸­çš„è¡¨å’Œæ–‡ä»¶ï¼š

ç°åœ¨å¯ä»¥å°†æ•°æ®å¼•å…¥åˆ°æ¹–å±‹ä¸­ã€‚ æœ‰å¤šç§æ–¹æ³•å¯ä»¥å®ç°æ­¤æ“ä½œï¼Œæ­¤å¤„å…ˆå°†æ–‡æœ¬æ–‡ä»¶ä¸‹è½½åˆ°æœ¬åœ°è®¡ç®—æœºï¼ˆæˆ–å®éªŒå®¤è™šæ‹Ÿæœºï¼Œå¦‚é€‚ç”¨ï¼‰ï¼Œç„¶åä¸Šä¼ åˆ°æ¹–å±‹ã€‚ 

1. ä» `https://github.com/MicrosoftLearning/dp-data/raw/main/products.csv` ä¸­ä¸‹è½½[æ•°æ®æ–‡ä»¶](https://github.com/MicrosoftLearning/dp-data/raw/main/products.csv)ï¼Œå°†å…¶å¦å­˜ä¸º *products.csv*ã€‚
1. è¿”å›åˆ°åŒ…å«æ¹–å±‹çš„ Web æµè§ˆå™¨é€‰é¡¹å¡ï¼Œç„¶ååœ¨â€œèµ„æºç®¡ç†å™¨â€çª—æ ¼ä¸­ï¼Œé€‰æ‹© **Files** æ–‡ä»¶å¤¹æ—è¾¹çš„ ... ã€‚  åˆ›å»ºåä¸º *products* çš„**æ–°å­æ–‡ä»¶å¤¹**ã€‚
1. åœ¨ åœ¨äº§å“æ–‡ä»¶å¤¹çš„èœå•ä¸Šï¼Œä»æœ¬åœ°è®¡ç®—æœºï¼ˆæˆ–å®éªŒå®¤ VMï¼Œå¦‚é€‚ç”¨ï¼‰**ä¸Šä¼ ***products.csv*æ–‡ä»¶ã€‚
1. ä¸Šä¼ æ–‡ä»¶åï¼Œé€‰æ‹© **products** æ–‡ä»¶å¤¹å¹¶éªŒè¯æ˜¯å¦å·²ä¸Šä¼ æ–‡ä»¶ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

    ![ä¸Šä¼ åˆ°æ¹–å±‹çš„ products.csv çš„å±å¹•å›¾ç‰‡ã€‚](Images/upload-products.png)
  
## æ¢ç´¢æ•°æ®å¸§ä¸­çš„æ•°æ®

ç°åœ¨å¯ä»¥åˆ›å»ºä¸€ä¸ª Fabric ç¬”è®°æœ¬æ¥å¤„ç†æ•°æ®ã€‚ ç¬”è®°æœ¬æä¾›äº†ä¸€ä¸ªäº¤äº’å¼ç¯å¢ƒï¼Œå¯åœ¨å…¶ä¸­ç¼–å†™å’Œè¿è¡Œä»£ç ã€‚

1. åœ¨å·¦ä¾§èœå•ä¸Šï¼Œé€‰æ‹©â€œ**åˆ›å»º**â€ã€‚ åœ¨â€œ*æ–°å»º*â€é¡µçš„â€œ*æ•°æ®å·¥ç¨‹*â€éƒ¨åˆ†ï¼Œé€‰æ‹©â€œ**ç¬”è®°æœ¬**â€ã€‚

    åˆ›å»ºå¹¶æ‰“å¼€åä¸ºâ€œ**ç¬”è®°æœ¬ 1**â€çš„æ–°ç¬”è®°æœ¬ã€‚

    ![æ–°å»ºç¬”è®°æœ¬çš„å±å¹•æˆªå›¾ã€‚](./Images/new-notebook.png)

1. Fabric ä¼šä¸ºä½ åˆ›å»ºçš„æ¯ä¸ªç¬”è®°æœ¬åˆ†é…ä¸€ä¸ªåç§°ï¼Œä¾‹å¦‚ç¬”è®°æœ¬ 1ã€ç¬”è®°æœ¬ 2 ç­‰ã€‚ç‚¹å‡»èœå•ä¸Š**ä¸»é¡µ**é€‰é¡¹å¡ä¸Šæ–¹çš„åç§°é¢æ¿ï¼Œå°†åç§°æ›´æ”¹ä¸ºæ›´å…·æè¿°æ€§çš„åç§°ã€‚
1. é€‰æ‹©ç¬¬ä¸€ä¸ªå•å…ƒæ ¼ï¼ˆå½“å‰æ˜¯ä»£ç å•å…ƒæ ¼ï¼‰ï¼Œç„¶ååœ¨å…¶å³ä¸Šè§’çš„åŠ¨æ€å·¥å…·æ ä¸­ï¼Œä½¿ç”¨ **Mâ†“** æŒ‰é’®å°†å•å…ƒæ ¼è½¬æ¢ä¸º Markdown å•å…ƒæ ¼ã€‚ ç„¶åï¼Œå•å…ƒæ ¼ä¸­åŒ…å«çš„æ–‡æœ¬å°†æ˜¾ç¤ºä¸ºå¸¦æ ¼å¼çš„æ–‡æœ¬ã€‚
1. ä½¿ç”¨ ğŸ–‰ï¼ˆç¼–è¾‘ï¼‰æŒ‰é’®å°†å•å…ƒæ ¼åˆ‡æ¢åˆ°ç¼–è¾‘æ¨¡å¼ï¼Œç„¶åä¿®æ”¹ Markdownï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

    ```markdown
    # Delta Lake tables 
    Use this notebook to explore Delta Lake functionality 
    ```

1. å•å‡»ç¬”è®°æœ¬ä¸­å•å…ƒæ ¼å¤–çš„ä»»æ„ä½ç½®ï¼Œå³å¯åœæ­¢ç¼–è¾‘ã€‚
1. åœ¨â€œèµ„æºç®¡ç†å™¨â€çª—æ ¼ä¸­ï¼Œé€‰æ‹©â€œæ·»åŠ æ•°æ®é¡¹â€ï¼Œç„¶åé€‰æ‹©â€œç°æœ‰æ•°æ®æºâ€ã€‚************ è¿æ¥åˆ°ä¹‹å‰åˆ›å»ºçš„æ¹–å±‹ã€‚
1. æ·»åŠ æ–°ä»£ç å•å…ƒæ ¼ï¼Œå¹¶æ·»åŠ ä»¥ä¸‹ä»£ç ï¼Œä»¥ä½¿ç”¨å®šä¹‰çš„æ¶æ„å°†äº§å“æ•°æ®è¯»å–åˆ° DataFrame ä¸­ï¼š

    ```python
   from pyspark.sql.types import StructType, IntegerType, StringType, DoubleType

   # define the schema
   schema = StructType() \
   .add("ProductID", IntegerType(), True) \
   .add("ProductName", StringType(), True) \
   .add("Category", StringType(), True) \
   .add("ListPrice", DoubleType(), True)

   df = spark.read.format("csv").option("header","true").schema(schema).load("Files/products/products.csv")
   # df now is a Spark DataFrame containing CSV data from "Files/products/products.csv".
   display(df)
    ```

> [!TIP]
> ä½¿ç”¨ V å½¢ Â« å›¾æ ‡éšè—æˆ–æ˜¾ç¤ºèµ„æºç®¡ç†å™¨çª—æ ¼ã€‚ è¿™ä½¿ä½ å¯ä»¥ä¸“æ³¨äºç¬”è®°æœ¬æˆ–æ–‡ä»¶ã€‚

1. ä½¿ç”¨å•å…ƒæ ¼å·¦ä¾§çš„**è¿è¡Œå•å…ƒæ ¼** (â–·) æŒ‰é’®è¿è¡Œå•å…ƒæ ¼ã€‚

> [!NOTE]
> ç”±äºè¿™æ˜¯ä½ ç¬¬ä¸€æ¬¡åœ¨æ­¤ç¬”è®°æœ¬ä¸­è¿è¡Œä»£ç ï¼Œå› æ­¤å¿…é¡»å¯åŠ¨ Spark ä¼šè¯ã€‚ è¿™æ„å‘³ç€ç¬¬ä¸€æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ä¸€åˆ†é’Ÿå·¦å³æ‰èƒ½å®Œæˆã€‚ åç»­è¿è¡Œé€Ÿåº¦ä¼šæ›´å¿«ã€‚

1. å•å…ƒæ ¼å®Œæˆåï¼ŒæŸ¥çœ‹å•å…ƒæ ¼ä¸‹æ–¹çš„è¾“å‡ºï¼Œè¾“å‡ºåº”å¦‚ä¸‹æ‰€ç¤ºï¼š

    ![products.csv æ•°æ®çš„å±å¹•å›¾ç‰‡ã€‚](Images/products-schema.png)
 
## åˆ›å»º Delta è¡¨

å¯ä»¥ä½¿ç”¨ *saveAsTable* æ–¹æ³•å°†æ•°æ®å¸§ä¿å­˜ä¸º Delta è¡¨ã€‚ Delta Lake æ”¯æŒåˆ›å»ºæ‰˜ç®¡è¡¨å’Œå¤–éƒ¨è¡¨ ã€‚

   * **æ‰˜ç®¡çš„**å¢é‡è¡¨å—ç›Šäºæ›´é«˜çš„æ€§èƒ½ï¼Œå› ä¸º Fabric åŒæ—¶ç®¡ç†æ¶æ„å…ƒæ•°æ®å’Œæ•°æ®æ–‡ä»¶ã€‚
   * **å¤–éƒ¨**è¡¨å…è®¸ä½¿ç”¨ Fabric ç®¡ç†çš„å…ƒæ•°æ®åœ¨å¤–éƒ¨å­˜å‚¨æ•°æ®ã€‚

### åˆ›å»ºæ‰˜ç®¡è¡¨

æ•°æ®æ–‡ä»¶æ˜¯åœ¨ **Tables** æ–‡ä»¶å¤¹ä¸­åˆ›å»ºçš„ã€‚

1. åœ¨ç¬¬ä¸€ä¸ªä»£ç å•å…ƒæ ¼è¿”å›çš„ç»“æœä¸‹ï¼Œä½¿ç”¨â€œ+ ä»£ç â€å›¾æ ‡æ·»åŠ æ–°çš„ä»£ç å•å…ƒæ ¼ã€‚

> [!TIP]
> è‹¥è¦æŸ¥çœ‹â€œ+ ä»£ç â€å›¾æ ‡ï¼Œè¯·å°†é¼ æ ‡ç§»åˆ°å½“å‰å•å…ƒæ ¼è¾“å‡ºçš„æ­£ä¸‹æ–¹å’Œå·¦ä¾§ã€‚ æˆ–è€…åœ¨èœå•æ ä¸­çš„â€œç¼–è¾‘â€é€‰é¡¹å¡ä¸Šï¼Œé€‰æ‹©â€œ**+ æ·»åŠ ä»£ç å•å…ƒæ ¼**â€ã€‚

1. è¦åˆ›å»ºæ‰˜ç®¡çš„ Delta è¡¨ï¼Œè¯·æ·»åŠ ä¸€ä¸ªæ–°å•å…ƒæ ¼ï¼Œè¾“å…¥ä»¥ä¸‹ä»£ç ï¼Œç„¶åè¿è¡Œè¯¥å•å…ƒæ ¼ï¼š

    ```python
   df.write.format("delta").saveAsTable("managed_products")
    ```

1. åœ¨èµ„æºç®¡ç†å™¨çª—æ ¼ä¸­ï¼Œâ€œ**åˆ·æ–°**â€ Tables æ–‡ä»¶å¤¹ï¼Œå¹¶å±•å¼€è¯¥èŠ‚ç‚¹ï¼ŒéªŒè¯æ˜¯å¦å·²åˆ›å»º **managed_products** è¡¨ã€‚

> [!NOTE]
> æ–‡ä»¶åæ—è¾¹çš„ä¸‰è§’å½¢å›¾æ ‡è¡¨ç¤º Delta è¡¨ã€‚

æ‰˜ç®¡è¡¨çš„æ–‡ä»¶å­˜å‚¨åœ¨æ¹–å±‹çš„ **Tables** æ–‡ä»¶å¤¹ä¸­ã€‚ å·²åˆ›å»ºåä¸º *managed_products* çš„æ–‡ä»¶å¤¹ï¼Œç”¨äºå­˜å‚¨è¡¨çš„ Parquet æ–‡ä»¶å’Œ delta_log æ–‡ä»¶å¤¹ ã€‚

### åˆ›å»ºå¤–éƒ¨è¡¨

è¿˜å¯ä»¥åˆ›å»ºå¤–éƒ¨è¡¨ï¼Œè¿™äº›è¡¨å¯èƒ½å­˜å‚¨åœ¨æ¹–å±‹ä»¥å¤–çš„æŸä¸ªä½ç½®ï¼Œæ¶æ„å…ƒæ•°æ®å­˜å‚¨åœ¨æ¹–å±‹ä¸­ã€‚

1. åœ¨èµ„æºç®¡ç†å™¨çª—æ ¼çš„â€œ...â€èœå•ä¸­ï¼Œ **Files** æ–‡ä»¶å¤¹çš„èœå•ï¼Œé€‰æ‹©â€œ**å¤åˆ¶ ABFS è·¯å¾„**â€ã€‚ ABFS è·¯å¾„æ˜¯æ¹–å±‹ Files æ–‡ä»¶å¤¹çš„å®Œå…¨é™å®šçš„è·¯å¾„ã€‚

1. åœ¨æ–°ä»£ç å•å…ƒä¸­ï¼Œç²˜è´´ ABFS è·¯å¾„ã€‚ æ·»åŠ ä»¥ä¸‹ä»£ç ï¼Œä½¿ç”¨å‰ªåˆ‡å’Œç²˜è´´å°† abfs_path æ’å…¥ä»£ç ä¸­çš„æ­£ç¡®ä½ç½®ï¼š

    ```python
   df.write.format("delta").saveAsTable("external_products", path="abfs_path/external_products")
    ```

1. å®Œæ•´è·¯å¾„åº”å¦‚ä¸‹æ‰€ç¤ºï¼š

    ```python
   abfss://workspace@tenant-onelake.dfs.fabric.microsoft.com/lakehousename.Lakehouse/Files/external_products
    ```

1. **è¿è¡Œ**å•å…ƒæ ¼ï¼Œå°†æ•°æ®å¸§ä¿å­˜ä¸º Files/external_products æ–‡ä»¶å¤¹ä¸­çš„å¤–éƒ¨è¡¨ã€‚

1. åœ¨èµ„æºç®¡ç†å™¨çª—æ ¼ä¸­ï¼Œâ€œ**åˆ·æ–°**â€ Tables æ–‡ä»¶å¤¹ï¼Œå¹¶å±•å¼€è¯¥èŠ‚ç‚¹ï¼ŒéªŒè¯å·²åˆ›å»ºåŒ…å«æ¶æ„å…ƒæ•°æ®çš„external_products è¡¨ã€‚

1. åœ¨èµ„æºç®¡ç†å™¨çª—æ ¼çš„â€œ...â€èœå•ä¸­ï¼Œ Files æ–‡ä»¶å¤¹çš„èœå•ï¼Œé€‰æ‹©â€œ **åˆ·æ–°**â€ã€‚ ç„¶åå±•å¼€â€œFilesâ€èŠ‚ç‚¹ï¼Œå¹¶éªŒè¯æ˜¯å¦å·²ä¸ºè¡¨çš„æ•°æ®æ–‡ä»¶åˆ›å»º external_products æ–‡ä»¶å¤¹ ã€‚

### æ¯”è¾ƒæ‰˜ç®¡è¡¨ä¸å¤–éƒ¨è¡¨

è®©æˆ‘ä»¬ä½¿ç”¨ %%sql magic å‘½ä»¤æ¥æ¢è®¨æ‰˜ç®¡è¡¨ä¸å¤–éƒ¨è¡¨ä¹‹é—´çš„å·®å¼‚ã€‚

1. åœ¨æ–°çš„ä»£ç å•å…ƒæ ¼ä¸­ï¼Œè¿è¡Œä»¥ä¸‹ä»£ç ï¼š

    ```python
   %%sql
   DESCRIBE FORMATTED managed_products;
    ```

1. åœ¨ç»“æœä¸­ï¼ŒæŸ¥çœ‹è¡¨çš„ä½ç½®å±æ€§ã€‚ å•å‡»â€œæ•°æ®ç±»å‹â€åˆ—ä¸­çš„â€œä½ç½®â€å€¼ä»¥æŸ¥çœ‹å®Œæ•´è·¯å¾„ã€‚ è¯·æ³¨æ„ï¼ŒOneLake å­˜å‚¨ä½ç½®ä»¥ /Tables/managed_products ç»“å°¾ã€‚

1. ä¿®æ”¹ DESCRIBE å‘½ä»¤ä»¥æ˜¾ç¤º external_products è¡¨çš„è¯¦ç»†ä¿¡æ¯ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

    ```python
   %%sql
   DESCRIBE FORMATTED external_products;
    ```

1. è¿è¡Œå•å…ƒæ ¼å¹¶åœ¨ç»“æœä¸­æŸ¥çœ‹è¡¨çš„ä½ç½®å±æ€§ã€‚ æ‰©å¤§æ•°æ®ç±»å‹åˆ—ä»¥æŸ¥çœ‹å®Œæ•´è·¯å¾„ï¼Œå¹¶æ³¨æ„ OneLake å­˜å‚¨ä½ç½®ä»¥ /Files/external_products ç»“å°¾ã€‚

1. åœ¨æ–°çš„ä»£ç å•å…ƒæ ¼ä¸­ï¼Œè¿è¡Œä»¥ä¸‹ä»£ç ï¼š

    ```python
   %%sql
   DROP TABLE managed_products;
   DROP TABLE external_products;
    ```

1. åœ¨èµ„æºç®¡ç†å™¨çª—æ ¼ä¸­ï¼Œâ€œ**åˆ·æ–°**â€ Tables æ–‡ä»¶å¤¹ï¼ŒéªŒè¯è¯¥èŠ‚ç‚¹ä¸­æ˜¯å¦æœªåˆ—å‡ºä»»ä½•è¡¨ã€‚
1. åœ¨èµ„æºç®¡ç†å™¨çª—æ ¼ä¸­ï¼Œâ€œ**åˆ·æ–°**â€ Files æ–‡ä»¶å¤¹ï¼Œå¹¶éªŒè¯æ˜¯å¦*å°šæœª*åˆ é™¤ external_productsã€‚ é€‰æ‹©æ­¤æ–‡ä»¶å¤¹å¯æŸ¥çœ‹ Parquet æ•°æ®æ–‡ä»¶å’Œ_delta_log æ–‡ä»¶å¤¹ã€‚ 

å¤–éƒ¨è¡¨çš„å…ƒæ•°æ®å·²åˆ é™¤ï¼Œä½†æ•°æ®æ–‡ä»¶æœªåˆ é™¤ã€‚

## ä½¿ç”¨ SQL åˆ›å»º Delta è¡¨

ç°åœ¨ï¼Œä½ å°†ä½¿ç”¨ %%sql magic å‘½ä»¤åˆ›å»º Delta è¡¨ã€‚ 

1. æ·»åŠ å¦ä¸€ä¸ªä»£ç å•å…ƒæ ¼ï¼Œå¹¶è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

    ```python
   %%sql
   CREATE TABLE products
   USING DELTA
   LOCATION 'Files/external_products';
    ```

1. åœ¨èµ„æºç®¡ç†å™¨çª—æ ¼çš„â€œ...â€èœå•ä¸­ï¼Œ **Tables** æ–‡ä»¶å¤¹çš„èœå•ï¼Œé€‰æ‹©â€œ**åˆ·æ–°**â€ã€‚ ç„¶åå±•å¼€â€œTablesâ€èŠ‚ç‚¹å¹¶éªŒè¯æ˜¯å¦åˆ—å‡ºäº†åä¸º *products* çš„æ–°è¡¨ã€‚ ç„¶åå±•å¼€è¡¨ä»¥æŸ¥çœ‹æ¶æ„ã€‚
1. æ·»åŠ å¦ä¸€ä¸ªä»£ç å•å…ƒæ ¼ï¼Œå¹¶è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

    ```python
   %%sql
   SELECT * FROM products;
    ```

## æ¢ç´¢è¡¨ç‰ˆæœ¬æ§åˆ¶

Delta è¡¨çš„äº‹åŠ¡å†å²è®°å½•å­˜å‚¨åœ¨ delta_log æ–‡ä»¶å¤¹çš„ JSON æ–‡ä»¶ä¸­ã€‚ å¯ä»¥ä½¿ç”¨æ­¤äº‹åŠ¡æ—¥å¿—æ¥ç®¡ç†æ•°æ®ç‰ˆæœ¬æ§åˆ¶ã€‚

1. å°†æ–°çš„ä»£ç å•å…ƒæ·»åŠ åˆ°ç¬”è®°æœ¬ï¼Œå¹¶è¿è¡Œä»¥ä¸‹ä»£ç ï¼Œä»¥å®ç°å±±åœ°è‡ªè¡Œè½¦ä»·æ ¼é™ä½ 10%ï¼š

    ```python
   %%sql
   UPDATE products
   SET ListPrice = ListPrice * 0.9
   WHERE Category = 'Mountain Bikes';
    ```

1. æ·»åŠ å¦ä¸€ä¸ªä»£ç å•å…ƒæ ¼ï¼Œå¹¶è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

    ```python
   %%sql
   DESCRIBE HISTORY products;
    ```

ç»“æœæ˜¾ç¤ºä¸ºè¯¥è¡¨è®°å½•çš„äº‹åŠ¡å†å²è®°å½•ã€‚

1. æ·»åŠ å¦ä¸€ä¸ªä»£ç å•å…ƒæ ¼ï¼Œå¹¶è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

    ```python
   delta_table_path = 'Files/external_products'
   # Get the current data
   current_data = spark.read.format("delta").load(delta_table_path)
   display(current_data)

   # Get the version 0 data
   original_data = spark.read.format("delta").option("versionAsOf", 0).load(delta_table_path)
   display(original_data)
    ```

è¿”å›ä¸¤ä¸ªç»“æœé›† - ä¸€ä¸ªåŒ…å«é™ä»·åçš„æ•°æ®ï¼Œå¦ä¸€ä¸ªæ˜¾ç¤ºæ•°æ®çš„åŸå§‹ç‰ˆæœ¬ã€‚

## ä½¿ç”¨ SQL æŸ¥è¯¢åˆ†æ Delta è¡¨æ•°æ®

ä½¿ç”¨ SQL magic å‘½ä»¤ï¼Œå¯ä»¥ä½¿ç”¨ SQL è¯­æ³•è€Œä¸æ˜¯ Pysparkã€‚ åœ¨è¿™é‡Œï¼Œä½ å°†ä½¿ç”¨ `SELECT` è¯­å¥ä»äº§å“è¡¨åˆ›å»ºä¸´æ—¶è§†å›¾ã€‚

1. æ·»åŠ æ–°çš„ä»£ç å•å…ƒï¼Œå¹¶è¿è¡Œä»¥ä¸‹ä»£ç æ¥åˆ›å»ºå’Œæ˜¾ç¤ºä¸´æ—¶è§†å›¾ï¼š

    ```python
   %%sql
   -- Create a temporary view
   CREATE OR REPLACE TEMPORARY VIEW products_view
   AS
       SELECT Category, COUNT(*) AS NumProducts, MIN(ListPrice) AS MinPrice, MAX(ListPrice) AS MaxPrice, AVG(ListPrice) AS AvgPrice
       FROM products
       GROUP BY Category;

   SELECT *
   FROM products_view
   ORDER BY Category;    
    ```

1. æ·»åŠ æ–°çš„ä»£ç å•å…ƒï¼Œå¹¶è¿è¡Œä»¥ä¸‹ä»£ç ï¼ŒæŒ‰äº§å“æ•°è¿”å›å‰ 10 ä¸ªç±»åˆ«ï¼š

    ```python
   %%sql
   SELECT Category, NumProducts
   FROM products_view
   ORDER BY NumProducts DESC
   LIMIT 10;
    ```

1. è¿”å›æ•°æ®åï¼Œé€‰æ‹©â€œ **+ æ–°å»ºå›¾è¡¨**â€œä»¥å±•ç¤ºå…¶ä¸­å»ºè®®çš„å›¾è¡¨ä¹‹ä¸€ã€‚

    ![SQL é€‰æ‹©è¯­å¥å’Œç»“æœçš„å±å¹•å›¾ç‰‡ã€‚](Images/sql-select.png)

æˆ–è€…ï¼Œå¯ä»¥ä½¿ç”¨ PySpark è¿è¡Œ SQL æŸ¥è¯¢ã€‚

1. æ·»åŠ æ–°ä»£ç å•å…ƒæ ¼å¹¶è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

    ```python
   from pyspark.sql.functions import col, desc

   df_products = spark.sql("SELECT Category, MinPrice, MaxPrice, AvgPrice FROM products_view").orderBy(col("AvgPrice").desc())
   display(df_products.limit(6))
    ```

## ä½¿ç”¨ Delta è¡¨å¯¹æ•°æ®è¿›è¡Œæµå¼å¤„ç†

Delta Lake æ”¯æŒæµå¼å¤„ç†æ•°æ®ã€‚ Delta è¡¨å¯ä»¥æ˜¯æ¥æ”¶å™¨ï¼Œä¹Ÿå¯ä»¥æ˜¯ä½¿ç”¨ Spark ç»“æ„åŒ–æµå¼å¤„ç† API åˆ›å»ºçš„æ•°æ®æµçš„æ•°æ®æº ã€‚ åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œä½ å°†ä½¿ç”¨ Delta è¡¨ä½œä¸ºæ¨¡æ‹Ÿç‰©è”ç½‘ (IoT) åœºæ™¯ä¸­éƒ¨åˆ†æµå¼å¤„ç†æ•°æ®çš„æ¥æ”¶å™¨ã€‚

1.  æ·»åŠ æ–°ä»£ç å•å…ƒæ ¼ï¼Œç„¶åæ·»åŠ ä»¥ä¸‹ä»£ç å¹¶è¿è¡Œï¼š

    ```python
    from notebookutils import mssparkutils
    from pyspark.sql.types import *
    from pyspark.sql.functions import *

    # Create a folder
    inputPath = 'Files/data/'
    mssparkutils.fs.mkdirs(inputPath)

    # Create a stream that reads data from the folder, using a JSON schema
    jsonSchema = StructType([
    StructField("device", StringType(), False),
    StructField("status", StringType(), False)
    ])
    iotstream = spark.readStream.schema(jsonSchema).option("maxFilesPerTrigger", 1).json(inputPath)

    # Write some event data to the folder
    device_data = '''{"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev2","status":"error"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"error"}
    {"device":"Dev2","status":"ok"}
    {"device":"Dev2","status":"error"}
    {"device":"Dev1","status":"ok"}'''

    mssparkutils.fs.put(inputPath + "data.txt", device_data, True)

    print("Source stream created...")
    ```

ç¡®ä¿æ¶ˆæ¯â€œ*å·²åˆ›å»ºæºæ•°æ®æµ...*â€ çš„æ¶ˆæ¯ã€‚ åˆšåˆšè¿è¡Œçš„ä»£ç åˆ›å»ºäº†ä¸€ä¸ªåŸºäºæ–‡ä»¶å¤¹çš„æµæ•°æ®æºï¼Œå…¶ä¸­ä¿å­˜äº†ä¸€äº›æ•°æ®ï¼Œè¡¨ç¤ºæ¥è‡ªè™šæ‹Ÿ IoT è®¾å¤‡çš„è¯»æ•°ã€‚

1. åœ¨æ–°çš„ä»£ç å•å…ƒæ ¼ä¸­ï¼Œæ·»åŠ å¹¶è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

    ```python
   # Write the stream to a delta table
   delta_stream_table_path = 'Tables/iotdevicedata'
   checkpointpath = 'Files/delta/checkpoint'
   deltastream = iotstream.writeStream.format("delta").option("checkpointLocation", checkpointpath).start(delta_stream_table_path)
   print("Streaming to delta sink...")
    ```

æ­¤ä»£ç ä»¥ Delta æ ¼å¼å°†æµå¼å¤„ç†è®¾å¤‡æ•°æ®å†™å…¥åä¸º iotdevicedata çš„æ–‡ä»¶å¤¹ã€‚ ç”±äºè¯¥æ–‡ä»¶å¤¹ä½ç½®çš„è·¯å¾„ä½äº Tables æ–‡ä»¶å¤¹ä¸­ï¼Œå› æ­¤å°†è‡ªåŠ¨ä¸ºå…¶åˆ›å»ºä¸€ä¸ªè¡¨ã€‚

1. åœ¨æ–°çš„ä»£ç å•å…ƒæ ¼ä¸­ï¼Œæ·»åŠ å¹¶è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

    ```python
   %%sql
   SELECT * FROM IotDeviceData;
    ```

æ­¤ä»£ç æŸ¥è¯¢ IotDeviceData è¡¨ï¼Œå…¶ä¸­åŒ…å«æ¥è‡ªæµå¼å¤„ç†æºçš„è®¾å¤‡æ•°æ®ã€‚

1. åœ¨æ–°çš„ä»£ç å•å…ƒæ ¼ä¸­ï¼Œæ·»åŠ å¹¶è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

    ```python
   # Add more data to the source stream
   more_data = '''{"device":"Dev1","status":"ok"}
   {"device":"Dev1","status":"ok"}
   {"device":"Dev1","status":"ok"}
   {"device":"Dev1","status":"ok"}
   {"device":"Dev1","status":"error"}
   {"device":"Dev2","status":"error"}
   {"device":"Dev1","status":"ok"}'''

   mssparkutils.fs.put(inputPath + "more-data.txt", more_data, True)
    ```

æ­¤ä»£ç å°†æ›´å¤šå‡è®¾çš„è®¾å¤‡æ•°æ®å†™å…¥æµå¼å¤„ç†æºã€‚

1. é‡æ–°è¿è¡ŒåŒ…å«ä»¥ä¸‹ä»£ç çš„å•å…ƒæ ¼ï¼š

    ```python
   %%sql
   SELECT * FROM IotDeviceData;
    ```

æ­¤ä»£ç å†æ¬¡æŸ¥è¯¢ IotDeviceData è¡¨ï¼Œè¯¥è¡¨ç°åœ¨åº”åŒ…æ‹¬å·²æ·»åŠ åˆ°æµå¼å¤„ç†æºçš„å…¶ä»–æ•°æ®ã€‚

1. åœ¨æ–°ä»£ç å•å…ƒæ ¼ä¸­ï¼Œæ·»åŠ ä»£ç ä»¥åœæ­¢æ•°æ®æµå¹¶è¿è¡Œå•å…ƒæ ¼ï¼š

    ```python
   deltastream.stop()
    ```

## æ¸…ç†èµ„æº

åœ¨æœ¬ç»ƒä¹ ä¸­ï¼Œä½ å·²äº†è§£å¦‚ä½•åœ¨ Microsoft Fabric ä¸­ä½¿ç”¨ Delta è¡¨ã€‚

å¦‚æœå·²å®Œæˆæ¹–å±‹æ¢ç´¢ï¼Œå¯åˆ é™¤ä¸ºæœ¬ç»ƒä¹ åˆ›å»ºçš„å·¥ä½œåŒºã€‚

1. åœ¨å·¦ä¾§æ ä¸­ï¼Œé€‰æ‹©å·¥ä½œåŒºçš„å›¾æ ‡ä»¥æŸ¥çœ‹å…¶åŒ…å«çš„æ‰€æœ‰é¡¹ã€‚
1. åœ¨ åœ¨å·¥å…·æ ä¸Šçš„èœå•ä¸­ï¼Œé€‰æ‹©â€œ**å·¥ä½œåŒºè®¾ç½®**â€ã€‚
1. åœ¨â€œå¸¸è§„â€éƒ¨åˆ†ä¸­ï¼Œé€‰æ‹©â€œ**åˆ é™¤æ­¤å·¥ä½œåŒº**â€ã€‚
